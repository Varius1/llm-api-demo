import kotlinx.serialization.SerialName
import kotlinx.serialization.Serializable
import kotlinx.serialization.encodeToString
import kotlinx.serialization.json.Json
import okhttp3.MediaType.Companion.toMediaType
import okhttp3.OkHttpClient
import okhttp3.Request
import okhttp3.RequestBody.Companion.toRequestBody
import java.util.concurrent.TimeUnit

// --- ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ OpenRouter API (ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼ Ñ OpenAI) ---

@Serializable
data class ChatMessage(
    val role: String,
    val content: String,
)

@Serializable
data class ChatRequest(
    val model: String,
    val messages: List<ChatMessage>,
    val temperature: Double? = null,
)

@Serializable
data class ChatChoice(
    val message: ChatMessage,
)

@Serializable
data class TokenUsage(
    @SerialName("prompt_tokens") val promptTokens: Int = 0,
    @SerialName("completion_tokens") val completionTokens: Int = 0,
    @SerialName("total_tokens") val totalTokens: Int = 0,
)

@Serializable
data class ChatResponse(
    val choices: List<ChatChoice> = emptyList(),
    val error: ChatError? = null,
    val usage: TokenUsage? = null,
    val model: String? = null,
)

@Serializable
data class ChatError(
    val message: String = "Unknown error",
    val code: Int? = null,
)

// --- ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ ---

private const val OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"
private const val DEFAULT_MODEL = "deepseek/deepseek-chat-v3.1"

private val json = Json {
    ignoreUnknownKeys = true
    encodeDefaults = false
}

private val client = OkHttpClient.Builder()
    .connectTimeout(30, TimeUnit.SECONDS)
    .readTimeout(120, TimeUnit.SECONDS)
    .build()

// --- ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ´Ğ»Ñ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ° ---

data class ModelConfig(
    val id: String,
    val tier: String,
    val displayName: String,
    val inputPricePerMillion: Double,
    val outputPricePerMillion: Double,
    val url: String,
)

private val BENCHMARK_MODELS = listOf(
    ModelConfig(
        id = "meta-llama/llama-3.3-70b-instruct",
        tier = "Ğ¡Ğ»Ğ°Ğ±Ğ°Ñ (Ğ´ĞµÑˆÑ‘Ğ²Ğ°Ñ)",
        displayName = "Llama 3.3 70B",
        inputPricePerMillion = 0.10,
        outputPricePerMillion = 0.32,
        url = "https://openrouter.ai/meta-llama/llama-3.3-70b-instruct",
    ),
    ModelConfig(
        id = "google/gemini-2.5-flash",
        tier = "Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ",
        displayName = "Gemini 2.5 Flash",
        inputPricePerMillion = 0.30,
        outputPricePerMillion = 2.50,
        url = "https://openrouter.ai/google/gemini-2.5-flash",
    ),
    ModelConfig(
        id = "anthropic/claude-sonnet-4",
        tier = "Ğ¡Ğ¸Ğ»ÑŒĞ½Ğ°Ñ (Ğ´Ğ¾Ñ€Ğ¾Ğ³Ğ°Ñ)",
        displayName = "Claude Sonnet 4",
        inputPricePerMillion = 3.00,
        outputPricePerMillion = 15.00,
        url = "https://openrouter.ai/anthropic/claude-sonnet-4",
    ),
)

private const val BENCHMARK_PROMPT =
    "ĞĞ±ÑŠÑÑĞ½Ğ¸ Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ ĞºĞ²Ğ°Ğ½Ñ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€Ğ° Ğ¸ Ğ² Ñ‡Ñ‘Ğ¼ ĞµĞ³Ğ¾ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¾Ñ‚ ĞºĞ»Ğ°ÑÑĞ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾. ĞÑ‚Ğ²ĞµÑ‚ Ğ´Ğ°Ğ¹ Ğ² 3-5 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ÑÑ…."

private val JUDGE_MODEL = ModelConfig(
    id = "google/gemini-2.5-flash",
    tier = "Ğ¡ÑƒĞ´ÑŒÑ",
    displayName = "Gemini 2.5 Flash",
    inputPricePerMillion = 0.30,
    outputPricePerMillion = 2.50,
    url = "https://openrouter.ai/google/gemini-2.5-flash",
)

// --- Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼Ğ¸ ---

data class BenchmarkResult(
    val model: ModelConfig,
    val response: String,
    val usage: TokenUsage?,
    val durationMs: Long,
    val costUsd: Double,
    val error: String? = null,
)

// --- ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° ---

fun sendMessageRaw(apiKey: String, messages: List<ChatMessage>, model: String, temperature: Double?): ChatResponse {
    val requestBody = json.encodeToString(
        ChatRequest(model = model, messages = messages, temperature = temperature)
    )

    val request = Request.Builder()
        .url(OPENROUTER_URL)
        .addHeader("Authorization", "Bearer $apiKey")
        .addHeader("Content-Type", "application/json")
        .post(requestBody.toRequestBody("application/json".toMediaType()))
        .build()

    client.newCall(request).execute().use { response ->
        val body = response.body?.string() ?: error("ĞŸÑƒÑÑ‚Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¾Ñ‚ ÑĞµÑ€Ğ²ĞµÑ€Ğ°")

        if (!response.isSuccessful) {
            error("HTTP ${response.code}: $body")
        }

        return json.decodeFromString<ChatResponse>(body)
    }
}

fun sendMessage(apiKey: String, messages: List<ChatMessage>, model: String, temperature: Double?): String {
    val chatResponse = sendMessageRaw(apiKey, messages, model, temperature)

    if (chatResponse.error != null) {
        error("API Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: ${chatResponse.error.message}")
    }

    return chatResponse.choices.firstOrNull()?.message?.content
        ?: error("ĞĞµÑ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ² choices")
}

fun calculateCost(usage: TokenUsage?, model: ModelConfig): Double {
    if (usage == null) return 0.0
    val inputCost = usage.promptTokens.toDouble() / 1_000_000 * model.inputPricePerMillion
    val outputCost = usage.completionTokens.toDouble() / 1_000_000 * model.outputPricePerMillion
    return inputCost + outputCost
}

fun runBenchmark(apiKey: String, prompt: String, models: List<ModelConfig>, temperature: Double?) {
    val messages = listOf(ChatMessage(role = "user", content = prompt))
    val results = mutableListOf<BenchmarkResult>()

    println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    println("â•‘              Ğ¡Ğ ĞĞ’ĞĞ•ĞĞ˜Ğ• ĞœĞĞ”Ğ•Ğ›Ğ•Ğ™ OpenRouter                   â•‘")
    println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    println()
    println("ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚: \"$prompt\"")
    println("Ğ¢ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ°: ${temperature ?: "Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ"}")
    println()

    for (model in models) {
        println("â”".repeat(62))
        println("â–¶ ${model.tier}: ${model.displayName}")
        println("  ID: ${model.id}")
        println("  Ğ¦ĞµĞ½Ğ°: \$${model.inputPricePerMillion}/M Ğ²Ñ…Ğ¾Ğ´ | \$${model.outputPricePerMillion}/M Ğ²Ñ‹Ñ…Ğ¾Ğ´")
        println()

        try {
            val startTime = System.nanoTime()
            val chatResponse = sendMessageRaw(apiKey, messages, model.id, temperature)
            val durationMs = (System.nanoTime() - startTime) / 1_000_000

            if (chatResponse.error != null) {
                val result = BenchmarkResult(model, "", null, durationMs, 0.0, chatResponse.error.message)
                results.add(result)
                println("  âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: ${chatResponse.error.message}")
                println()
                continue
            }

            val content = chatResponse.choices.firstOrNull()?.message?.content ?: "(Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚)"
            val usage = chatResponse.usage
            val cost = calculateCost(usage, model)

            val result = BenchmarkResult(model, content, usage, durationMs, cost)
            results.add(result)

            println("  ĞÑ‚Ğ²ĞµÑ‚:")
            content.lines().forEach { println("    $it") }
            println()
            println("  â±  Ğ’Ñ€ĞµĞ¼Ñ: ${durationMs}Ğ¼Ñ (${String.format("%.1f", durationMs / 1000.0)}Ñ)")
            if (usage != null) {
                println("  ğŸ“Š Ğ¢Ğ¾ĞºĞµĞ½Ñ‹: ${usage.promptTokens} Ğ²Ñ…Ğ¾Ğ´ + ${usage.completionTokens} Ğ²Ñ‹Ñ…Ğ¾Ğ´ = ${usage.totalTokens} Ğ²ÑĞµĞ³Ğ¾")
            }
            println("  ğŸ’° Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ: \$${String.format("%.6f", cost)}")
        } catch (e: Exception) {
            val result = BenchmarkResult(model, "", null, 0, 0.0, e.message)
            results.add(result)
            println("  âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: ${e.message}")
        }
        println()
    }

    printComparison(results)
    runJudge(apiKey, prompt, results)
}

fun printComparison(results: List<BenchmarkResult>) {
    val successful = results.filter { it.error == null }
    if (successful.isEmpty()) {
        println("ĞĞµÑ‚ ÑƒÑĞ¿ĞµÑˆĞ½Ñ‹Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ.")
        return
    }

    println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    println("â•‘                    Ğ¡Ğ’ĞĞ”ĞĞĞ¯ Ğ¢ĞĞ‘Ğ›Ğ˜Ğ¦Ğ                         â•‘")
    println("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")

    val header = String.format(
        "â•‘ %-18s â”‚ %8s â”‚ %6s â”‚ %6s â”‚ %10s â•‘",
        "ĞœĞ¾Ğ´ĞµĞ»ÑŒ", "Ğ’Ñ€ĞµĞ¼Ñ", "Ğ’Ñ…Ğ¾Ğ´", "Ğ’Ñ‹Ñ…Ğ¾Ğ´", "Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ"
    )
    println(header)
    println("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")

    for (r in results) {
        val timeStr = if (r.error != null) "ĞĞ¨Ğ˜Ğ‘ĞšĞ" else "${String.format("%.1f", r.durationMs / 1000.0)}Ñ"
        val inTokens = r.usage?.promptTokens?.toString() ?: "-"
        val outTokens = r.usage?.completionTokens?.toString() ?: "-"
        val costStr = if (r.error != null) "-" else "\$${String.format("%.6f", r.costUsd)}"
        val name = r.model.displayName.take(18)

        println(
            String.format(
                "â•‘ %-18s â”‚ %8s â”‚ %6s â”‚ %6s â”‚ %10s â•‘",
                name, timeStr, inTokens, outTokens, costStr
            )
        )
    }

    println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    println()

    val fastest = successful.minByOrNull { it.durationMs }
    val cheapest = successful.minByOrNull { it.costUsd }
    val longest = successful.maxByOrNull { it.response.length }

    println("ğŸ“ˆ Ğ’Ğ«Ğ’ĞĞ”Ğ«:")
    println("â”€".repeat(62))
    if (fastest != null)
        println("  ğŸš€ Ğ‘Ñ‹ÑÑ‚Ñ€ĞµĞµ Ğ²ÑĞµÑ…: ${fastest.model.displayName} (${String.format("%.1f", fastest.durationMs / 1000.0)}Ñ)")
    if (cheapest != null)
        println("  ğŸ’° Ğ”ĞµÑˆĞµĞ²Ğ»Ğµ Ğ²ÑĞµÑ…: ${cheapest.model.displayName} (\$${String.format("%.6f", cheapest.costUsd)})")
    if (longest != null)
        println("  ğŸ“ Ğ¡Ğ°Ğ¼Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ñ‹Ğ¹: ${longest.model.displayName} (${longest.response.length} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²)")
    println()

    println("ğŸ”— Ğ¡ÑÑ‹Ğ»ĞºĞ¸ Ğ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸:")
    for (r in results) {
        println("  â€¢ ${r.model.displayName}: ${r.model.url}")
    }
    println()
}

fun runJudge(apiKey: String, originalPrompt: String, results: List<BenchmarkResult>) {
    val successful = results.filter { it.error == null }
    if (successful.size < 2) return

    println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    println("â•‘            ğŸ§‘â€âš–ï¸ ĞĞ¦Ğ•ĞĞšĞ ĞšĞĞ§Ğ•Ğ¡Ğ¢Ğ’Ğ (Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ-ÑÑƒĞ´ÑŒÑ)               â•‘")
    println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    println("  Ğ¡ÑƒĞ´ÑŒÑ: ${JUDGE_MODEL.displayName} (${JUDGE_MODEL.id})")
    println()

    val answersBlock = successful.joinToString("\n\n") { r ->
        "--- ${r.model.displayName} (${r.model.tier}) ---\n${r.response}"
    }

    val judgePrompt = """
Ğ¢Ñ‹ â€” ÑĞºÑĞ¿ĞµÑ€Ñ‚-Ğ¾Ñ†ĞµĞ½Ñ‰Ğ¸Ğº Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹. Ğ¢ĞµĞ±Ğµ Ğ´Ğ°Ğ½ Ğ¾Ğ´Ğ¸Ğ½ Ğ¸ Ñ‚Ğ¾Ñ‚ Ğ¶Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ¾Ñ‚ ${successful.size} Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹.

Ğ˜ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ: "$originalPrompt"

ĞÑ‚Ğ²ĞµÑ‚Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹:
$answersBlock

ĞÑ†ĞµĞ½Ğ¸ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¿Ğ¾ ĞºÑ€Ğ¸Ñ‚ĞµÑ€Ğ¸ÑĞ¼:
1. Ğ¢Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ (Ñ„Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ)
2. ĞŸĞ¾Ğ»Ğ½Ğ¾Ñ‚Ğ° (Ğ½Ğ°ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ Ñ€Ğ°ÑĞºÑ€Ñ‹Ñ‚Ğ° Ñ‚ĞµĞ¼Ğ°)
3. ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ·Ñ‹ĞºĞ° (Ğ³Ñ€Ğ°Ğ¼Ğ¾Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ, Ğ½ĞµÑ‚ Ğ»Ğ¸ Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ğ², Ğ¼ÑƒÑĞ¾Ñ€Ğ½Ñ‹Ñ… ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ², ÑĞ¼ĞµÑˆĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²)
4. Ğ¡Ğ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸ (ÑƒĞ»Ğ¾Ğ¶Ğ¸Ğ»ÑÑ Ğ»Ğ¸ Ğ² 3-5 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹)

Ğ”Ğ°Ğ¹ ĞºÑ€Ğ°Ñ‚ĞºÑƒÑ Ğ¾Ñ†ĞµĞ½ĞºÑƒ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (1-2 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ) Ğ¸ Ğ½Ğ°Ğ·Ğ¾Ğ²Ğ¸ Ğ»ÑƒÑ‡ÑˆĞ¸Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚. ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼.
""".trim()

    try {
        val startTime = System.nanoTime()
        val messages = listOf(ChatMessage(role = "user", content = judgePrompt))
        val response = sendMessageRaw(apiKey, messages, JUDGE_MODEL.id, 0.3)
        val durationMs = (System.nanoTime() - startTime) / 1_000_000

        if (response.error != null) {
            println("  âŒ ĞÑˆĞ¸Ğ±ĞºĞ° ÑÑƒĞ´ÑŒĞ¸: ${response.error.message}")
            return
        }

        val verdict = response.choices.firstOrNull()?.message?.content ?: "(Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚)"
        val usage = response.usage
        val cost = calculateCost(usage, JUDGE_MODEL)

        println("  Ğ’ĞµÑ€Ğ´Ğ¸ĞºÑ‚:")
        verdict.lines().forEach { println("    $it") }
        println()
        println("  â±  Ğ’Ñ€ĞµĞ¼Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸: ${durationMs}Ğ¼Ñ (${String.format("%.1f", durationMs / 1000.0)}Ñ)")
        if (usage != null) {
            println("  ğŸ“Š Ğ¢Ğ¾ĞºĞµĞ½Ñ‹ ÑÑƒĞ´ÑŒĞ¸: ${usage.promptTokens} Ğ²Ñ…Ğ¾Ğ´ + ${usage.completionTokens} Ğ²Ñ‹Ñ…Ğ¾Ğ´ = ${usage.totalTokens}")
        }
        println("  ğŸ’° Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ¾Ñ†ĞµĞ½ĞºĞ¸: \$${String.format("%.6f", cost)}")
        println()
    } catch (e: Exception) {
        println("  âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğµ ÑÑƒĞ´ÑŒĞ¸: ${e.message}")
        println()
    }
}

fun main(args: Array<String>) {
    val apiKey = System.getenv("OPENROUTER_API_KEY")
        ?: run {
            print("Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ²Ğ°Ñˆ OpenRouter API ĞºĞ»ÑÑ‡: ")
            readlnOrNull()?.trim() ?: error("API ĞºĞ»ÑÑ‡ Ğ½Ğµ Ğ²Ğ²ĞµĞ´Ñ‘Ğ½")
        }

    if (args.contains("--compare")) {
        val customPrompt = args.indexOf("--prompt").let { idx ->
            if (idx >= 0 && idx + 1 < args.size) args[idx + 1] else null
        }
        val temperature = args.indexOf("--temp").let { idx ->
            if (idx >= 0 && idx + 1 < args.size) args[idx + 1].toDoubleOrNull() else null
        }

        runBenchmark(apiKey, customPrompt ?: BENCHMARK_PROMPT, BENCHMARK_MODELS, temperature)
        return
    }

    val model = System.getenv("LLM_MODEL") ?: DEFAULT_MODEL
    var temperature = System.getenv("LLM_TEMPERATURE")?.toDoubleOrNull()

    println("=== LLM CLI Chat ===")
    println("ĞœĞ¾Ğ´ĞµĞ»ÑŒ: $model")
    println("Ğ¢ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ°: ${temperature ?: "Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ (1.0)"}")
    println("ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹: /temp 0.7 â€” Ñ‚ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ°, /compare â€” ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸, exit â€” Ğ²Ñ‹Ñ…Ğ¾Ğ´")
    println("Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ (Ğ´Ğ²Ğ¾Ğ¹Ğ½Ğ¾Ğ¹ Enter â€” Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ)")
    println()

    while (true) {
        print("Ğ’Ñ‹: ")
        val lines = mutableListOf<String>()
        var emptyCount = 0
        while (true) {
            val line = readlnOrNull() ?: break
            if (line.isEmpty()) {
                emptyCount++
                if (emptyCount >= 2) break
                lines.add(line)
            } else {
                emptyCount = 0
                val trimmed = line.trim()
                if (lines.isEmpty() && trimmed.startsWith("/temp")) {
                    val newTemp = trimmed.removePrefix("/temp").trim().toDoubleOrNull()
                    temperature = newTemp
                    println("Ğ¢ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ°: ${temperature ?: "Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ (1.0)"}\n")
                    emptyCount = 2
                    break
                }
                if (lines.isEmpty() && trimmed == "/compare") {
                    println()
                    runBenchmark(apiKey, BENCHMARK_PROMPT, BENCHMARK_MODELS, temperature)
                    emptyCount = 2
                    break
                }
                if (lines.isEmpty() && (trimmed.equals("exit", ignoreCase = true) || trimmed.equals("quit", ignoreCase = true))) {
                    println("Ğ”Ğ¾ ÑĞ²Ğ¸Ğ´Ğ°Ğ½Ğ¸Ñ!")
                    return
                }
                lines.add(line)
            }
        }

        val input = lines.joinToString("\n").trim()

        if (input.isEmpty()) continue

        val messages = listOf(ChatMessage(role = "user", content = input))

        try {
            val reply = sendMessage(apiKey, messages, model, temperature)
            println("\nLLM:\n$reply\n")
        } catch (e: Exception) {
            println("\nĞÑˆĞ¸Ğ±ĞºĞ°: ${e.message}\n")
        }
    }
}
